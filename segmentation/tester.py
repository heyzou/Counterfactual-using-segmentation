import os
import time
import torch
import datetime
import numpy as np
import imageio

import torch.nn as nn
from torch.autograd import Variable
from torchvision.utils import save_image
from torchvision import transforms

import cv2
import PIL
from .unet import unet
from PIL import Image


from .utils import *

def transformer(resize, totensor, normalize, centercrop, imsize):
    options = []
    if centercrop:
        options.append(transforms.CenterCrop(160))
    if resize:
        options.append(transforms.Resize((imsize,imsize), interpolation=PIL.Image.NEAREST))
    if totensor:
        options.append(transforms.ToTensor())
    if normalize:
        options.append(transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)))
    transform = transforms.Compose(options)
    
    return transform

def make_dataset(dir):
    images = []
    assert os.path.isdir(dir), '%s is not a valid directory' % dir

    f = dir.split('/')[-1].split('_')[-1]
    print (dir, len([name for name in os.listdir(dir) if os.path.isfile(os.path.join(dir, name))]))
    for i in range(len([name for name in os.listdir(dir) if os.path.isfile(os.path.join(dir, name))])):
        img = str(i) + '.jpg'
        path = os.path.join(dir, img)
        images.append(path)
   
    return images

class Tester(object):
    def __init__(self, config):
        # exact model and loss
        self.model = config.model

        # Model hyper-parameters
        self.imsize = config.imsize
        self.parallel = config.parallel

        # self.total_step = config.total_step
        # self.batch_size = config.batch_size
        # self.num_workers = config.num_workers
        # self.g_lr = config.g_lr
        # self.lr_decay = config.lr_decay
        # self.beta1 = config.beta1
        # self.beta2 = config.beta2
        self.pretrained_model = config.pretrained_model

        self.img_path = config.img_path
        # self.label_path = config.label_path 
        self.log_path = config.log_path
        # self.model_save_path = config.model_save_path
        self.sample_path = config.sample_path
        self.log_step = config.log_step
        self.sample_step = config.sample_step
        # self.model_save_step = config.model_save_step
        self.version = config.version

        # Path
        self.log_path = os.path.join(config.log_path, self.version)
        self.sample_path = os.path.join(config.sample_path, self.version)
        # self.model_save_path = os.path.join(config.model_save_path, self.version)
        self.test_label_path = config.test_label_path
        self.test_color_label_path = config.test_color_label_path
        self.test_image_path = config.test_image_path

        # Test size and model
        self.test_size = config.test_size
        self.model_name = config.model_name

        # GIF ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.gif_save_path = "./results/gif"
        os.makedirs(self.gif_save_path, exist_ok=True)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        self.segmented_images = []
        
        self.build_model()

    def test(self, image: torch.Tensor, step: int = None):
        # [C, H, W] ã®å ´åˆã€ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
        img_tensor = image.unsqueeze(0) if image.ndim == 3 else image
        img_tensor = img_tensor.cuda()

        # æ¨è«–
        self.G.eval()
        labels_predict = self.G(img_tensor)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³çµæœã®ç”Ÿæˆ
        labels_predict_plain = generate_label_plain(labels_predict, self.imsize)
        labels_predict_color = generate_label(labels_predict, self.imsize)

        # ğŸ”¹ ä¿å­˜æ™‚ã®ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´
        step_suffix = f"_step_{step}" if step is not None else ""
    
        cv2.imwrite(os.path.join(self.test_label_path, f'predict{step_suffix}.png'),
                labels_predict_plain[0])
        save_image(labels_predict_color[0],
               os.path.join(self.test_color_label_path, f'predict_color{step_suffix}.png'))

        # ğŸ”¹ GIF ç”¨ã«ç”»åƒã‚’ä¿å­˜
        self.segmented_images.append(labels_predict_color[0].cpu().permute(1, 2, 0).numpy())

        print(f"Single-image test done. Saved as predict{step_suffix}.png")

    def build_model(self):
        """ ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€å­¦ç¿’æ¸ˆã¿é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ """

        # ğŸ”¹ ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        self.G = unet().cuda()
        if self.parallel:
            self.G = nn.DataParallel(self.G)

        print("== ãƒ¢ãƒ‡ãƒ«æ§‹é€  ==")
        print(self.G)  # ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã‚’å‡ºåŠ›

        # ğŸ”¹ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        model_path = "segmentation/models/parsenet/model.pth"

        print(f"Loading model weights from: {model_path}")

        try:
            checkpoint = torch.load(model_path, map_location="cuda" if torch.cuda.is_available() else "cpu")

            # ğŸ”¹ ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®å†…å®¹ã‚’ç¢ºèª
            if isinstance(checkpoint, dict) and "model_state_dict" in checkpoint:
                self.G.load_state_dict(checkpoint["model_state_dict"], strict=False)
            else:
                self.G.load_state_dict(checkpoint, strict=False)

            print("âœ… ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰æˆåŠŸ")
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    
        # ğŸ”¹ å­¦ç¿’æ¸ˆã¿ã®é‡ã¿ãŒé©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        for name, param in self.G.named_parameters():
            print(f"{name}: {param.mean().item()}")  # å¹³å‡å€¤ã‚’è¡¨ç¤º
            break  # 1ã¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã¿ç¢ºèªã™ã‚Œã°OK

    def get_segmentation_prob(self, image: torch.Tensor):
        """
        ç”»åƒã«å¯¾ã—ã¦ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é©ç”¨ã—ã€å„ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡åˆ†å¸ƒã‚’è¿”ã™
        """
        self.G.eval()
        # with torch.no_grad():
        logits = self.G(image.cuda())  # [N, C, H, W]
        probs = torch.nn.functional.softmax(logits, dim=1)  # ç¢ºç‡åˆ†å¸ƒã«å¤‰æ›
        return probs

    def save_gif(self):
        """ä¿å­˜ã—ãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”»åƒã‹ã‚‰ GIF ã‚’ä½œæˆ"""
        gif_path = os.path.join(self.gif_save_path, "segmentation_animation.gif")

        # ğŸ”¹ ç”»åƒã‚’ uint8 ã«å¤‰æ›
        segmented_images_uint8 = [(img * 255).astype(np.uint8) for img in self.segmented_images]

        imageio.mimsave(gif_path, segmented_images_uint8, duration=0.2)
        print(f"GIF saved at: {gif_path}")